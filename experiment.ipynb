{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import vgg\n",
    "import matplotlib.pyplot as plt\n",
    "from sys import stderr\n",
    "\n",
    "CONTENT_LAYER = 'relu4_2'\n",
    "STYLE_LAYERS = ('relu1_1', 'relu2_1', 'relu3_1', 'relu4_1', 'relu5_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def imread(path):\n",
    "    img = scipy.misc.imread(path).astype(np.float)\n",
    "    if len(img.shape) == 2:\n",
    "        # grayscale\n",
    "        img = np.dstack((img,img,img))\n",
    "    return img\n",
    "\n",
    "def imsave(path, img):\n",
    "    img = np.clip(img, 0, 255).astype(np.uint8)\n",
    "    scipy.misc.imsave(path, img)\n",
    "    \n",
    "def _conv_layer(input, weights, bias):\n",
    "    conv = tf.nn.conv2d(input, tf.constant(weights), strides=(1, 1, 1, 1),\n",
    "            padding='SAME')\n",
    "    return tf.nn.bias_add(conv, bias)\n",
    "\n",
    "\n",
    "def _pool_layer(input):\n",
    "    return tf.nn.max_pool(input, ksize=(1, 2, 2, 1), strides=(1, 2, 2, 1),\n",
    "            padding='SAME')\n",
    "\n",
    "def _tensor_size(tensor):\n",
    "    from operator import mul\n",
    "    return reduce(mul, (d.value for d in tensor.get_shape()), 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network = \"imagenet-vgg-verydeep-19.mat\"\n",
    "initial = None\n",
    "content_dir = \"examples/1-content.jpg\"\n",
    "styles_dir = [\"examples/1-style.jpg\"]\n",
    "iterations = 200\n",
    "content_weight = 5e0\n",
    "style_weight = 1e2\n",
    "style_blend_weights = [1]\n",
    "tv_weight = 1e2\n",
    "learning_rate = 1e1\n",
    "print_iterations = 50\n",
    "checkpoint_iterations = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "content = imread(content_dir)\n",
    "styles = [imread(style) for style in styles_dir]\n",
    "target_shape = content.shape\n",
    "for i in range(len(styles)):\n",
    "    style_scale = 1.0\n",
    "    styles[i] = scipy.misc.imresize(styles[i], style_scale *\n",
    "            target_shape[1] / styles[i].shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-09658cb89066>:80 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 1/200\n",
      "  content loss: 2.13958e+06\n",
      "    style loss: 5.859e+07\n",
      "       tv loss: 26.1588\n",
      "    total loss: 6.07297e+07\n",
      "Iteration 2/200\n",
      "Iteration 3/200\n",
      "Iteration 4/200\n",
      "Iteration 5/200\n",
      "Iteration 6/200\n",
      "Iteration 7/200\n",
      "Iteration 8/200\n",
      "Iteration 9/200\n",
      "Iteration 10/200\n",
      "Iteration 11/200\n",
      "Iteration 12/200\n",
      "Iteration 13/200\n",
      "Iteration 14/200\n",
      "Iteration 15/200\n",
      "Iteration 16/200\n",
      "Iteration 17/200\n",
      "Iteration 18/200\n",
      "Iteration 19/200\n",
      "Iteration 20/200\n",
      "Iteration 21/200\n",
      "Iteration 22/200\n",
      "Iteration 23/200\n",
      "Iteration 24/200\n",
      "Iteration 25/200\n",
      "Iteration 26/200\n",
      "Iteration 27/200\n",
      "Iteration 28/200\n",
      "Iteration 29/200\n",
      "Iteration 30/200\n",
      "Iteration 31/200\n",
      "Iteration 32/200\n",
      "Iteration 33/200\n",
      "Iteration 34/200\n",
      "Iteration 35/200\n",
      "Iteration 36/200\n",
      "Iteration 37/200\n",
      "Iteration 38/200\n",
      "Iteration 39/200\n",
      "Iteration 40/200\n",
      "Iteration 41/200\n",
      "Iteration 42/200\n",
      "Iteration 43/200\n",
      "Iteration 44/200\n",
      "Iteration 45/200\n",
      "Iteration 46/200\n",
      "Iteration 47/200\n",
      "Iteration 48/200\n",
      "Iteration 49/200\n",
      "Iteration 50/200\n",
      "Iteration 51/200\n",
      "  content loss: 1.45329e+06\n",
      "    style loss: 570945\n",
      "       tv loss: 136704\n",
      "    total loss: 2.16094e+06\n",
      "Iteration 52/200\n",
      "Iteration 53/200\n",
      "Iteration 54/200\n",
      "Iteration 55/200\n",
      "Iteration 56/200\n",
      "Iteration 57/200\n",
      "Iteration 58/200\n",
      "Iteration 59/200\n",
      "Iteration 60/200\n",
      "Iteration 61/200\n",
      "Iteration 62/200\n",
      "Iteration 63/200\n",
      "Iteration 64/200\n",
      "Iteration 65/200\n",
      "Iteration 66/200\n",
      "Iteration 67/200\n",
      "Iteration 68/200\n",
      "Iteration 69/200\n",
      "Iteration 70/200\n",
      "Iteration 71/200\n",
      "Iteration 72/200\n",
      "Iteration 73/200\n",
      "Iteration 74/200\n",
      "Iteration 75/200\n",
      "Iteration 76/200\n",
      "Iteration 77/200\n",
      "Iteration 78/200\n",
      "Iteration 79/200\n",
      "Iteration 80/200\n",
      "Iteration 81/200\n",
      "Iteration 82/200\n",
      "Iteration 83/200\n",
      "Iteration 84/200\n",
      "Iteration 85/200\n",
      "Iteration 86/200\n",
      "Iteration 87/200\n",
      "Iteration 88/200\n",
      "Iteration 89/200\n",
      "Iteration 90/200\n",
      "Iteration 91/200\n",
      "Iteration 92/200\n",
      "Iteration 93/200\n",
      "Iteration 94/200\n",
      "Iteration 95/200\n",
      "Iteration 96/200\n",
      "Iteration 97/200\n",
      "Iteration 98/200\n",
      "Iteration 99/200\n",
      "Iteration 100/200\n",
      "Iteration 101/200\n",
      "  content loss: 1.00637e+06\n",
      "    style loss: 341948\n",
      "       tv loss: 98766.5\n",
      "    total loss: 1.44708e+06\n",
      "Iteration 102/200\n",
      "Iteration 103/200\n",
      "Iteration 104/200\n",
      "Iteration 105/200\n",
      "Iteration 106/200\n",
      "Iteration 107/200\n",
      "Iteration 108/200\n",
      "Iteration 109/200\n",
      "Iteration 110/200\n",
      "Iteration 111/200\n",
      "Iteration 112/200\n",
      "Iteration 113/200\n",
      "Iteration 114/200\n",
      "Iteration 115/200\n",
      "Iteration 116/200\n",
      "Iteration 117/200\n",
      "Iteration 118/200\n",
      "Iteration 119/200\n",
      "Iteration 120/200\n",
      "Iteration 121/200\n",
      "Iteration 122/200\n",
      "Iteration 123/200\n",
      "Iteration 124/200\n",
      "Iteration 125/200\n",
      "Iteration 126/200\n",
      "Iteration 127/200\n",
      "Iteration 128/200\n",
      "Iteration 129/200\n",
      "Iteration 130/200\n",
      "Iteration 131/200\n",
      "Iteration 132/200\n",
      "Iteration 133/200\n",
      "Iteration 134/200\n",
      "Iteration 135/200\n",
      "Iteration 136/200\n",
      "Iteration 137/200\n",
      "Iteration 138/200\n",
      "Iteration 139/200\n",
      "Iteration 140/200\n",
      "Iteration 141/200\n",
      "Iteration 142/200\n",
      "Iteration 143/200\n",
      "Iteration 144/200\n",
      "Iteration 145/200\n",
      "Iteration 146/200\n",
      "Iteration 147/200\n",
      "Iteration 148/200\n",
      "Iteration 149/200\n",
      "Iteration 150/200\n",
      "Iteration 151/200\n",
      "  content loss: 931886\n",
      "    style loss: 424272\n",
      "       tv loss: 83008.9\n",
      "    total loss: 1.43917e+06\n",
      "Iteration 152/200\n",
      "Iteration 153/200\n",
      "Iteration 154/200\n",
      "Iteration 155/200\n",
      "Iteration 156/200\n",
      "Iteration 157/200\n",
      "Iteration 158/200\n",
      "Iteration 159/200\n",
      "Iteration 160/200\n",
      "Iteration 161/200\n",
      "Iteration 162/200\n",
      "Iteration 163/200\n",
      "Iteration 164/200\n",
      "Iteration 165/200\n",
      "Iteration 166/200\n",
      "Iteration 167/200\n",
      "Iteration 168/200\n",
      "Iteration 169/200\n",
      "Iteration 170/200\n",
      "Iteration 171/200\n",
      "Iteration 172/200\n",
      "Iteration 173/200\n",
      "Iteration 174/200\n",
      "Iteration 175/200\n",
      "Iteration 176/200\n",
      "Iteration 177/200\n",
      "Iteration 178/200\n",
      "Iteration 179/200\n",
      "Iteration 180/200\n",
      "Iteration 181/200\n",
      "Iteration 182/200\n",
      "Iteration 183/200\n",
      "Iteration 184/200\n",
      "Iteration 185/200\n",
      "Iteration 186/200\n",
      "Iteration 187/200\n",
      "Iteration 188/200\n",
      "Iteration 189/200\n",
      "Iteration 190/200\n",
      "Iteration 191/200\n",
      "Iteration 192/200\n",
      "Iteration 193/200\n",
      "Iteration 194/200\n",
      "Iteration 195/200\n",
      "Iteration 196/200\n",
      "Iteration 197/200\n",
      "Iteration 198/200\n",
      "Iteration 199/200\n",
      "Iteration 200/200\n",
      "  content loss: 858246\n",
      "    style loss: 273438\n",
      "       tv loss: 72688.3\n",
      "    total loss: 1.20437e+06\n"
     ]
    }
   ],
   "source": [
    "shape = (1,) + content.shape\n",
    "style_shapes = [(1,) + style.shape for style in styles]\n",
    "content_features = {}\n",
    "style_features = [{} for _ in styles]\n",
    "\n",
    "# compute content features in feedforward mode\n",
    "g = tf.Graph()\n",
    "with g.as_default(), g.device('/cpu:0'), tf.Session() as sess:\n",
    "    image = tf.placeholder('float', shape=shape)\n",
    "    net, mean_pixel = vgg.net(network, image)\n",
    "    content_pre = np.array([vgg.preprocess(content, mean_pixel)])\n",
    "    content_features[CONTENT_LAYER] = net[CONTENT_LAYER].eval(\n",
    "            feed_dict={image: content_pre})\n",
    "\n",
    "# compute style features in feedforward mode\n",
    "for i in range(len(styles)):\n",
    "    g = tf.Graph()\n",
    "    with g.as_default(), g.device('/cpu:0'), tf.Session() as sess:\n",
    "        image = tf.placeholder('float', shape=style_shapes[i])\n",
    "        net, _ = vgg.net(network, image)\n",
    "        style_pre = np.array([vgg.preprocess(styles[i], mean_pixel)])\n",
    "        for layer in STYLE_LAYERS:\n",
    "            features = net[layer].eval(feed_dict={image: style_pre})\n",
    "            features = np.reshape(features, (-1, features.shape[3]))\n",
    "            gram = np.matmul(features.T, features) / features.size\n",
    "            style_features[i][layer] = gram\n",
    "\n",
    "# make stylized image using backpropogation\n",
    "with tf.Graph().as_default():\n",
    "    # init image\n",
    "    noise = np.random.normal(size=shape, scale=np.std(content) * 0.1)\n",
    "    initial = tf.random_normal(shape) * 0.256\n",
    "    image = tf.Variable(initial)\n",
    "    net, _ = vgg.net(network, image)\n",
    "\n",
    "    # content loss\n",
    "    content_loss = content_weight * (2 * tf.nn.l2_loss(\n",
    "            net[CONTENT_LAYER] - content_features[CONTENT_LAYER]) /\n",
    "            content_features[CONTENT_LAYER].size)\n",
    "    \n",
    "    # style loss\n",
    "    style_loss = 0\n",
    "    for i in range(len(styles)):\n",
    "        style_losses = []\n",
    "        for style_layer in STYLE_LAYERS:\n",
    "            layer = net[style_layer]\n",
    "            _, height, width, number = map(lambda i: i.value, layer.get_shape())\n",
    "            size = height * width * number\n",
    "            feats = tf.reshape(layer, (-1, number))\n",
    "            gram = tf.matmul(tf.transpose(feats), feats) / size\n",
    "            style_gram = style_features[i][style_layer]\n",
    "            style_losses.append(2 * tf.nn.l2_loss(gram - style_gram) / style_gram.size)\n",
    "        style_loss += style_weight * style_blend_weights[i] * reduce(tf.add, style_losses)\n",
    "        \n",
    "    # total variation denoising\n",
    "    tv_y_size = _tensor_size(image[:,1:,:,:])\n",
    "    tv_x_size = _tensor_size(image[:,:,1:,:])\n",
    "    tv_loss = tv_weight * 2 * (\n",
    "            (tf.nn.l2_loss(image[:,1:,:,:] - image[:,:shape[1]-1,:,:]) /\n",
    "                tv_y_size) +\n",
    "            (tf.nn.l2_loss(image[:,:,1:,:] - image[:,:,:shape[2]-1,:]) /\n",
    "                tv_x_size))\n",
    "    # overall loss\n",
    "    loss = content_loss + style_loss + tv_loss\n",
    "\n",
    "    # optimizer setup\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "    def print_progress(i, last=False):\n",
    "        stderr.write('Iteration %d/%d\\n' % (i + 1, iterations))\n",
    "        if last or (print_iterations and i % print_iterations == 0):\n",
    "            stderr.write('  content loss: %g\\n' % content_loss.eval())\n",
    "            stderr.write('    style loss: %g\\n' % style_loss.eval())\n",
    "            stderr.write('       tv loss: %g\\n' % tv_loss.eval())\n",
    "            stderr.write('    total loss: %g\\n' % loss.eval())\n",
    "    # optimization\n",
    "    best_loss = float('inf')\n",
    "    best = None\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "        for i in range(iterations):\n",
    "            last_step = (i == iterations - 1)\n",
    "            print_progress(i, last=last_step)\n",
    "            train_step.run()\n",
    "\n",
    "            if (checkpoint_iterations and i % checkpoint_iterations == 0) or last_step:\n",
    "                this_loss = loss.eval()\n",
    "                if this_loss < best_loss:\n",
    "                    best_loss = this_loss\n",
    "                    best = image.eval()\n",
    "                    output = vgg.unprocess(best.reshape(shape[1:]), mean_pixel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imsave('output.jpg', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
